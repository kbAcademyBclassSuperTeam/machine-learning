{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0bf31",
   "metadata": {
    "id": "39c0bf31"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q3cOP2lv6J9g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3cOP2lv6J9g",
    "outputId": "f669666c-4f8b-4e2c-d1df-77f15fb6d631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fHnwL4x6XcI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fHnwL4x6XcI",
    "outputId": "3ebf0ac1-8960-4907-fa32-845246d4c8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks/scam\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Colab Notebooks/scam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZyDvs79X6jWr",
   "metadata": {
    "id": "ZyDvs79X6jWr"
   },
   "outputs": [],
   "source": [
    "# !unzip -qq \"data.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505af29",
   "metadata": {
    "id": "e505af29"
   },
   "source": [
    "- wav는 매 순간의 음압을 측정하여 그 수치를 저장한 형태이기 때문에 그 자체로 음악을 분석하기에 적합하지 않음 (음의 높이와 세기를 듣는것이지 순간의 음압을 듣는게 아니기 때문)\n",
    "- 푸리에 변환과 같은 변환 기법을 이용하여 시간 축의 데이터를 주파수 축의 데이터로 바꿔줘야할 필요가 있음\n",
    "- 푸리에 변환 대신 푸리에 변환과 유사한 Constant-Q 변환을 사용\n",
    "- Constant-Q 변환은 주파수 축이 로그 단위로 변환되고, 각 주파수에 따라 해상도가 다양하게 처리되기 때문에(저주파는 저해상도, 고주파는 고해상도) 음악을 처리하는 데에 푸리에 변환보다 유리\n",
    "- 주파수 대역을 저장할 리스트 audio_cqt 선언\n",
    "- constant-Q 변환할 때는 변환할 오디오 데이터와 sampling rate가 필요\n",
    "- 해당 데이터에서는 sampling rate가 모두 동일하므로 따로 처리가 필요하지 않음\n",
    "- 여기서는 Constant-Q 변환을 사용해 오디오 데이터를 주파수 대역으로 변환\n",
    "- 변환에는 앞서 준비한 데이터를 가져와 사용하며, Constant-Q 변환에는 librosa.cqt 함수를 사용\n",
    "- 여기서 n_bins는 옥타브 단계 및 개수를, bins_per_octave는 한 옥타브가 가지는 단계를 의미\n",
    "- 라벨에 대해선 원 핫 인코딩을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa550c",
   "metadata": {
    "id": "b8fa550c"
   },
   "outputs": [],
   "source": [
    "def get_target_data(data_dir):\n",
    "    audio_path_list = []\n",
    "    audio_path_list.extend(glob(os.path.join(data_dir,'*.wav')))\n",
    "    label_list = [1] * len(audio_path_list)\n",
    "           \n",
    "    return audio_path_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54bc8b",
   "metadata": {
    "id": "1a54bc8b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "all_audio_path, all_label = get_target_data('/content/drive/MyDrive/Colab Notebooks/scam/data/위급상황/원천데이터/sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596af3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6596af3f",
    "outputId": "cd077405-f256-4102-964a-bf77ccef43fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 1073)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_audio_path), len(all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a23e38",
   "metadata": {
    "id": "50a23e38"
   },
   "outputs": [],
   "source": [
    "all_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HS_Zmyb0m703",
   "metadata": {
    "id": "HS_Zmyb0m703"
   },
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8e1d1",
   "metadata": {
    "id": "b3e8e1d1"
   },
   "outputs": [],
   "source": [
    "def get_normal_data(data_dir):\n",
    "    normal_path_list = []\n",
    "    \n",
    "    for case_name in os.listdir(data_dir):\n",
    "        current_path = os.path.join(data_dir, case_name)\n",
    "        for case_name_2 in os.listdir(current_path):\n",
    "            current_path_2 = os.path.join(current_path, case_name_2)\n",
    "            for case_name_3 in os.listdir(current_path_2):\n",
    "                current_path_3 = os.path.join(current_path_2, case_name_3)\n",
    "                normal_path_list.extend(glob(os.path.join(current_path_3,'*.wav')))\n",
    "    \n",
    "    label_list = [0] * len(normal_path_list)\n",
    "           \n",
    "    return normal_path_list, label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41f417",
   "metadata": {
    "id": "3c41f417"
   },
   "outputs": [],
   "source": [
    "all_normal_path, all_normal_label = get_normal_data('/content/drive/MyDrive/Colab Notebooks/scam/data/정상/원천데이터/KrespSpeech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4130da5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4130da5",
    "outputId": "dee62d04-0285-4a69-805b-453ece8e619c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5463, 5463)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_normal_path), len(all_normal_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00abbe9",
   "metadata": {
    "id": "e00abbe9"
   },
   "source": [
    "## 경로를 이용해서 모든 데이터 가져온 후 음성데이터에서 \n",
    "\n",
    "주요 개념\n",
    "\n",
    "1. 푸리에 변환\n",
    "\n",
    "음성 신호에 푸리에 변환을 적용하면 각 진동수 성분이 그 음성에 얼마나 들어있는지 알 수 있습니다.\n",
    "\n",
    "쉽게 설명하면 음성 신호에 저음이 얼마나 있고, 고음이 얼마나 있는지를 정량적으로 구할 수 있습니다.\n",
    "\n",
    "2. STFT(Short Time Fourier Transform)\n",
    "\n",
    "음성을 작게(0.01초 수준) 잘라서 각 작은 조각에 푸리에 변환을 적용할 수 있습니다.\n",
    "이것을 STFT라고 부르고 일반적으로 이 결과의 L2 norm을 Spectrogram이라고 부릅니다.\n",
    "\n",
    "3. Melspectrogram\n",
    "\n",
    "Melspectrogram은 Spectrogram에 mel-filter라는 필터를 적용해서 얻어집니다. 이는 사람의 청각 기관이 저음에서 주파\n",
    "수 변화에 민감하고 고음에서는 주파수의 변화에 덜 민감한 특징을 반영하고 있습니다.\n",
    "\n",
    "- Function and Option\n",
    "\n",
    "torchaudio에서는 다음과 같이 Spectrogram과 Melspectrogram을 얻을 수 있는 프로세스를 정의할 수 있습니다.\n",
    "AmplitudeToDB는 power단위의 Spectrogram 또는 Melspectrogram을 dB(로그) 단위로 변환해 줍니다.\n",
    "\n",
    "1. win_length\n",
    "\n",
    "음성을 작은 조각으로 자를 때 작은 조각의 크기를 의미합니다.\n",
    "자연어 처리 분야에서는 25ms의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 400에 해당하는 값입니다. (16000/40)\n",
    "22050Hz의 파일이기 때문에 552로 설정하겠습니다. (22050/40, 소수점 올림)\n",
    "\n",
    "2. n_fft\n",
    "\n",
    "win_length의 크기로 잘린 음성의 작은 조각은 0으로 Padding 되어서 n_fft로 크기가 맞춰집니다. 그렇게 padding 된 조각\n",
    "에 푸리에 변환이 적용됩니다. 따라서 n_fft는 win_length보다 크거나 같아야 하고 일반적으로 속도를 위해서 값으로 설정\n",
    "합니다.\n",
    "win_length의 크기가 552이기 때문에 512는 될 수 없고, 1024는 너무 크다고 생각하여 win_length와 똑같이 552로 설정하\n",
    "겠습니다.\n",
    "\n",
    "3. hop_length\n",
    "\n",
    "음성을 작은 조각으로 자를 때, 자르는 간격을 의미합니다. 즉, 이 길이만큼 옆으로 밀면서 작은 조각을 얻습니다.\n",
    "일반 적으로 10ms의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 160에 해당하는 값입니다. (16000/100)\n",
    "22050Hz의 파일이기 때문에 221로 설정하겠습니다. (22050/100)\n",
    "\n",
    "4. n_mels\n",
    "\n",
    "적용할 mel filter의 개수를 의미합니다\n",
    "\n",
    "n_mel이 80이면 Melspectrogram의 주파수 방향 성분 수는 80인 것입니다.\n",
    "\n",
    "\n",
    "마지막으로 Spectrogram과 Melspectrogram의 해상력에 대해 설명하겠습니다.\n",
    "\n",
    "win_length가 커질수록 주파수 성분에 대한 해상력은 높아지지만(정밀해진다) 시간 성분에 대한 해상력은 낮아지게 됩니다.\n",
    "\n",
    "즉, 더 정밀한 주파수 분포를 얻을 수 있으나 시간에 따른 주파수 변화를 관찰하기가 어려워집니다.\n",
    "\n",
    "반대로 win_length가 작은 경우에는 주파수 성분에 대한 해상력은 낮아지지만, 시간 성분에 대한 해상력은 높아지게 됩니다.\n",
    "\n",
    "따라서 적절한 값을 찾는 것이 중요합니다.\n",
    "\n",
    "또한 n_fft를 키우는 경우 주파수 성분의 수는 증가할지 몰라도 실제 주파수의 해상력은 증가하지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UXk7HUeam_UE",
   "metadata": {
    "id": "UXk7HUeam_UE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11774ea5",
   "metadata": {
    "id": "11774ea5"
   },
   "source": [
    "'마지막으로 spectrogram과 melspectrogram의 해상력에 대해 설명하겠습니다. win_length가 커질수록 주파수 성분에 대한 해상력은 높아지지만, 즉 더 정밀해지지만, 시간 성분에 대한 해상력은 낮아지게 됩니다. 즉, 더 정밀한 주파수 분포를 얻을 수 있으나 시간에 따른 주파수 변화를 관찰하기가 어려워집니다. 반대로 win_length가 작은 경우에는 주파수 성분에 대한 해상력은 낮아지지만, 시간 성분에 대한 해상력은 높아지게 됩니다. 따라서 적절한 값을 찾는 것이 중요합니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727fcff",
   "metadata": {
    "id": "8727fcff"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "df_log = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u_8aJ6HqnDPK",
   "metadata": {
    "id": "u_8aJ6HqnDPK"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5acca",
   "metadata": {
    "id": "03b5acca"
   },
   "outputs": [],
   "source": [
    "\n",
    "for path in all_audio_path:\n",
    "    y, sr = librosa.load(path)\n",
    "\n",
    "    n_fft = int(np.ceil(0.025 * sr))\n",
    "    win_length = int(np.ceil(0.025 * sr))\n",
    "    hop_length = int(np.ceil(0.01 * sr))\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, win_length=win_length, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "#     S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    df.append(S)\n",
    "#     df_log.append(S_dB)\n",
    "    target.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oHjvVTJ-er9r",
   "metadata": {
    "id": "oHjvVTJ-er9r"
   },
   "source": [
    " n_mels 는 에러가 나지않는 최대 값을 해야함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df8d86",
   "metadata": {
    "id": "f5df8d86"
   },
   "outputs": [],
   "source": [
    "for path in all_normal_path:\n",
    "    y, sr = librosa.load(path)\n",
    "\n",
    "    n_fft = int(np.ceil(0.025 * sr))\n",
    "    win_length = int(np.ceil(0.025 * sr))\n",
    "    hop_length = int(np.ceil(0.01 * sr))\n",
    "\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, win_length=win_length, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "\n",
    "#     S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    df.append(S)  \n",
    "#     df_log.append(S_dB)\n",
    "    target.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LLjT3j9CvK6V",
   "metadata": {
    "id": "LLjT3j9CvK6V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d03e7",
   "metadata": {
    "id": "e77d03e7"
   },
   "outputs": [],
   "source": [
    "arr_df = []\n",
    "arr_target = []\n",
    "import itertools\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df[i].shape[0] * df[i].shape[1] < 50000:\n",
    "        arr_df.append( list(itertools.chain(*df[i]))) \n",
    "        arr_target.append(target[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79529023",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79529023",
    "outputId": "d3c88ed1-8996-4526-c2a4-1fd9385d23d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 69760\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(item) for item in arr_df)\n",
    "print('최대 길이 :',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cdf39",
   "metadata": {
    "id": "052cdf39"
   },
   "outputs": [],
   "source": [
    "\n",
    "for sentence in arr_df:\n",
    "    while len(sentence) < max_len:\n",
    "        sentence.append(0)\n",
    "\n",
    "padded_np = np.array(arr_df)\n",
    "padded_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fb887",
   "metadata": {
    "id": "820fb887"
   },
   "outputs": [],
   "source": [
    "padded_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e12dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "051e12dd",
    "outputId": "1b419b38-3320-4cb9-c056-0a3ea86fa8cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_np = np.array(arr_target)\n",
    "target_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044809e",
   "metadata": {
    "id": "4044809e"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(padded_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e59abf",
   "metadata": {
    "id": "a6e59abf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_np,\n",
    "    target_np,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559aaebd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "559aaebd",
    "outputId": "13c6c495-7829-429c-f51b-4d798ac52744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7971014492753623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "pred = DT.predict(X_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d9927",
   "metadata": {
    "id": "398d9927"
   },
   "source": [
    "## 머신러닝 모델 중에서 성능이 가장 뛰어났던 DecisionTreeClassifier를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b378e23",
   "metadata": {
    "id": "2b378e23"
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(model, 'DecisionTree_model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4ecdd",
   "metadata": {
    "id": "02c4ecdd"
   },
   "source": [
    "# CNN 으로 돌리기 ( 80, 249 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5a473",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bf5a473",
    "outputId": "9ef54e07-8932-417c-9f5e-adee4fd185be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 19840)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e6176",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f37e6176",
    "outputId": "42285b7e-bac4-4f92-e91e-8bdeec70db98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 80, 248)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = padded_np.reshape(499, 80, 248)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3927936",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3927936",
    "outputId": "b0f6c5d0-ab62-49b2-98d0-62b102d0876a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 80, 248, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_np = np.expand_dims(b, -1)\n",
    "re_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb69ef0",
   "metadata": {
    "id": "0fb69ef0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    re_np,\n",
    "    target_np,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ad046",
   "metadata": {
    "id": "076ad046"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cb7ac",
   "metadata": {
    "id": "d30cb7ac"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "def model_CNN_build():\n",
    "    model = Sequential()\n",
    "    input = Input(shape=(80,248,1))\n",
    "\n",
    "    output = Conv2D(128, 3, strides=1, padding='same', activation='relu')(input)\n",
    "    output = MaxPool2D(pool_size=(2,2), strides=2, padding='same')(output)\n",
    "    Dropout(0.15)\n",
    "    \n",
    "    output = Conv2D(256, 3, strides=1, padding='same', activation='relu')(output)\n",
    "    output = MaxPool2D(pool_size=(2,2), strides=2, padding='same')(output)\n",
    "    Dropout(0.15)\n",
    "\n",
    "    output = Conv2D(512, 3, strides=1, padding='same', activation='relu')(output)\n",
    "    output = MaxPool2D(pool_size=(2,2), strides=2, padding='same')(output)\n",
    "    Dropout(0.15)\n",
    "\n",
    "    output=Flatten()(output)\n",
    "    Dropout(0.2),\n",
    "    output=Dense(512, activation='relu')(output)\n",
    "    output=Dense(256, activation='relu')(output)\n",
    "    output=Dense(128, activation='relu')(output)\n",
    "\n",
    "    output=Dense(1, activation='sigmoid')(output)\n",
    "    \n",
    "    model = Model(inputs=[input], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90bb53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa90bb53",
    "outputId": "715405de-9a39-4d82-b1e7-26fa063f8a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 80, 248, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 80, 248, 128)      1280      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 40, 124, 128)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 40, 124, 256)      295168    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 20, 62, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 20, 62, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 10, 31, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 158720)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               81265152  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,906,113\n",
      "Trainable params: 82,906,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_CNN_build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44bba2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e44bba2e",
    "outputId": "741c4a90-7b0d-4f20-b276-247ff0f5be9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: acc improved from -inf to 0.49216, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 2: acc improved from 0.49216 to 0.60502, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 3: acc improved from 0.60502 to 0.76489, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 4: acc did not improve from 0.76489\n",
      "\n",
      "Epoch 5: acc improved from 0.76489 to 0.78683, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 6: acc did not improve from 0.78683\n",
      "\n",
      "Epoch 7: acc improved from 0.78683 to 0.82759, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 8: acc improved from 0.82759 to 0.87147, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 9: acc did not improve from 0.87147\n",
      "\n",
      "Epoch 10: acc improved from 0.87147 to 0.88401, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 11: acc improved from 0.88401 to 0.88715, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 12: acc improved from 0.88715 to 0.92476, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 13: acc improved from 0.92476 to 0.94984, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 14: acc improved from 0.94984 to 0.97179, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 15: acc improved from 0.97179 to 0.97492, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 16: acc improved from 0.97492 to 0.98433, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 17: acc improved from 0.98433 to 0.98746, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 18: acc improved from 0.98746 to 0.99060, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 19: acc improved from 0.99060 to 0.99373, saving model to CNN_best_model.h5\n",
      "\n",
      "Epoch 20: acc did not improve from 0.99373\n",
      "\n",
      "Epoch 21: acc did not improve from 0.99373\n",
      "\n",
      "Epoch 22: acc did not improve from 0.99373\n",
      "\n",
      "Epoch 23: acc did not improve from 0.99373\n",
      "Epoch 23: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('CNN_best_model.h5', monitor='acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "hist = model.fit(X_train, y_train, epochs=100, verbose=0, callbacks=[es,mc], batch_size=128, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d09fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f26d09fc",
    "outputId": "520bd598-521e-4d63-d612-476393b6a49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 42ms/step - loss: 1.2928 - acc: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2928054332733154, 0.7900000214576721]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fdfa6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d74fdfa6",
    "outputId": "338d8797-52c8-4113-f7b1-4e647147e0a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9361702127659575, 0.7096774193548387)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "pred = pred.round()\n",
    "pred = pred.flatten() # 1차원으로 변경\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "recall_score(y_test,pred), precision_score(y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "398d9927",
    "02c4ecdd"
   ],
   "name": "scam_detection-version4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
